{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe3939ba-e2f9-4b27-b20b-39d3abf41236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('jazz', 31), ('patchen', 30), ('poetry', 17), ('musician', 11), ('poems', 11), ('new', 10), ('private', 10), ('experiments', 9), ('musicians', 8), ('many', 8), ('detective', 8), ('hero', 8), ('well', 7), ('rexroth', 7), ('like', 6), ('myth', 6), ('anger', 6), ('may', 5), ('first', 5), ('work', 5), ('almost', 5), ('love', 5), ('kind', 5), ('symbols', 5), ('must', 5), (\"n't\", 5), ('angry', 5), ('poetry-and-jazz', 4), ('san', 4), ('francisco', 4), ('kenneth', 4), ('reading', 4), ('modern', 4), ('often', 4), ('early', 4), ('form', 4), ('approach', 4), ('book', 4), ('world', 4), ('man', 4), ('death', 4), ('art', 4), ('feeling', 4), ('one', 4), ('ca', 4), ('hold', 4), ('han', 4), ('seen', 3), ('writing', 3), ('tristano', 3)]\n",
      "\n",
      " [('jazz', 31), ('patch', 30), ('mus', 25), ('poetry', 17), ('poem', 14), ('us', 12), ('expery', 11), ('new', 10), ('priv', 10), ('read', 9), ('hero', 9), ('work', 9), ('detect', 9), ('writ', 8), ('ear', 8), ('many', 8), ('wel', 7), ('rexro', 7), ('poet', 7), ('myth', 7), ('lik', 6), ('form', 6), ('lov', 6), ('ang', 6), ('may', 5), ('first', 5), ('almost', 5), ('world', 5), ('kind', 5), ('ey', 5), ('symbol', 5), ('art', 5), ('must', 5), (\"n't\", 5), ('angry', 5), ('poetry-and-jazz', 4), ('san', 4), ('francisco', 4), ('kenne', 4), ('tak', 4), ('modern', 4), ('oft', 4), ('approach', 4), ('book', 4), ('publ', 4), ('revolv', 4), ('man', 4), ('dea', 4), ('ref', 4), ('draw', 4)]\n",
      "\n",
      " [('jazz', 31), ('patchen', 30), ('musician', 19), ('poetry', 17), ('poem', 14), ('new', 10), ('private', 10), ('experiment', 9), ('hero', 9), ('detective', 9), ('many', 8), ('well', 7), ('rexroth', 7), ('work', 7), ('myth', 7), ('like', 6), ('form', 6), ('love', 6), ('anger', 6), ('may', 5), ('first', 5), ('almost', 5), ('kind', 5), ('eye', 5), ('symbol', 5), ('must', 5), (\"n't\", 5), ('angry', 5), ('poetry-and-jazz', 4), ('san', 4), ('francisco', 4), ('kenneth', 4), ('reading', 4), ('modern', 4), ('school', 4), ('often', 4), ('read', 4), ('early', 4), ('approach', 4), ('book', 4), ('world', 4), ('man', 4), ('death', 4), ('reference', 4), ('art', 4), ('feeling', 4), ('one', 4), ('ca', 4), ('hold', 4), ('han', 4)]\n",
      " - Word               \t - Lancaster           \t - Lemma              \t Lemma SoP\n",
      " jazz                 \t jazz                 \t jazz                 \t jazz\n",
      " patchen              \t patch                \t patchen              \t patchen\n",
      " poetry               \t poetry               \t poetry               \t poetry\n",
      " musician             \t mus                  \t musician             \t musician\n",
      " poems                \t poem                 \t poem                 \t poems\n",
      " new                  \t new                  \t new                  \t new\n",
      " private              \t priv                 \t private              \t private\n",
      " experiments          \t expery               \t experiment           \t experiment\n",
      " musicians            \t mus                  \t musician             \t musicians\n",
      " many                 \t many                 \t many                 \t many\n",
      " detective            \t detect               \t detective            \t detective\n",
      " hero                 \t hero                 \t hero                 \t hero\n",
      " well                 \t wel                  \t well                 \t well\n",
      " rexroth              \t rexro                \t rexroth              \t rexroth\n",
      " like                 \t lik                  \t like                 \t like\n",
      " myth                 \t myth                 \t myth                 \t myth\n",
      " anger                \t ang                  \t anger                \t anger\n",
      " may                  \t may                  \t may                  \t may\n",
      " first                \t first                \t first                \t first\n",
      " work                 \t work                 \t work                 \t work\n",
      " almost               \t almost               \t almost               \t almost\n",
      " love                 \t lov                  \t love                 \t love\n",
      " kind                 \t kind                 \t kind                 \t kind\n",
      " symbols              \t symbol               \t symbol               \t symbols\n",
      " must                 \t must                 \t must                 \t must\n",
      " n't                  \t n't                  \t n't                  \t n't\n",
      " angry                \t angry                \t angry                \t angry\n",
      " poetry-and-jazz      \t poetry-and-jazz      \t poetry-and-jazz      \t poetry-and-jazz\n",
      " san                  \t san                  \t san                  \t san\n",
      " francisco            \t francisco            \t francisco            \t francisco\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "# nltk.download('brown')\n",
    "# nltk.download(\"wordnet\")\n",
    "\n",
    "corpus = brown.words('cg73')\n",
    "\n",
    "text_cg73 = ''\n",
    "for w in corpus:\n",
    "    text_cg73 += w +' '\n",
    "\n",
    "# Eliminar etiquetas HTML y XML\n",
    "import re\n",
    "text = re.sub(r'<[^>]+>', '', text_cg73)\n",
    "\n",
    "# Eliminar emoticones\n",
    "text = re.sub(r'(:\\)|:-\\)|;\\)|\\(:|:-\\(|:-\\||:O|:\\'\\(|:\\*|:P|:D|:S|XD|:\\/)', '', text)\n",
    "\n",
    "# Tokenizar el texto\n",
    "tokens = nltk.word_tokenize(text)\n",
    "\n",
    "# Convertir a minúsculas y eliminar signos de puntuación\n",
    "pattern = re.compile(r'\\w+')\n",
    "tokens = [token.lower() for token in tokens if pattern.match(token)]\n",
    "\n",
    "# Obtener palabras vacías en inglés\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Eliminar palabras vacías\n",
    "tokens = [token for token in tokens if token not in stop_words]\n",
    "\n",
    "# Calcular la frecuencia de cada palabra\n",
    "from collections import Counter\n",
    "frecuencia_palabras = Counter(tokens)\n",
    "\n",
    "# Obtener las 50 palabras más frecuentes\n",
    "palabras_mas_frecuentes = frecuencia_palabras.most_common(50)\n",
    "print(palabras_mas_frecuentes)\n",
    "\n",
    "# Obtener las 50 stems más frecuentes\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "st = LancasterStemmer()\n",
    "text_lemma_lancaster = [ st.stem(i) for i in tokens ]\n",
    "\n",
    "stemFrequency = FreqDist(word for word in text_lemma_lancaster)\n",
    "print(\"\\n\",stemFrequency.most_common(50))\n",
    "stem_mas_frecuente = stemFrequency.most_common(50)\n",
    "\n",
    "# Obtener las 50 lemmas más frecuentes\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "lemmas = [ wordnet_lemmatizer.lemmatize(word) for word in tokens ]\n",
    "\n",
    "lemmasFrequency = FreqDist(word for word in lemmas)\n",
    "print(\"\\n\",lemmasFrequency.most_common(50))\n",
    "\n",
    "# lemmatizacion indicando PoS\n",
    "lemmasSoP = [ wordnet_lemmatizer.lemmatize(word, pos=\"v\") for word in tokens ]\n",
    "\n",
    "\n",
    "# representación tabular de los primeros 30 tokens\n",
    "most_frequent_words = FreqDist(word for word in tokens)\n",
    "most_frequent_words = most_frequent_words.most_common(30)\n",
    "\n",
    "print(\" {0:<20} \\t {1:<20}  \\t {2:<20} \\t {3}\"\n",
    "    .format(\"- Word\",\"- Lancaster\",\"- Lemma\", \"Lemma SoP\"))\n",
    "for word, frecuency in most_frequent_words :\n",
    "    print( \" {0:<20} \\t {1:<20} \\t {2:<20} \\t {3}\"\n",
    "    .format( word, \n",
    "             st.stem(word), \n",
    "             wordnet_lemmatizer.lemmatize(word), \n",
    "             wordnet_lemmatizer.lemmatize(word, pos=\"v\") ) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
